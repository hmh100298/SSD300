{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_SSD300.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "12l7XyRXSUwrOlLhunj0pFX9bigmcyOtt",
      "authorship_tag": "ABX9TyMLtj35+5H0yYntTmZ2n2ma",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hmh100298/SSD300/blob/main/Model_SSD300.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FFk6d660XBf"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "#from keras.model import Model\n",
        "from keras.layers import Input, Lambda, Activation, Conv2D, MaxPooling2D, ZeroPadding2D, Reshape, Concatenate\n",
        "from keras.regularizers import l2\n",
        "import keras.backend as K\n",
        "\n",
        "from anchor_box import AnchorBoxes\n",
        "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
        "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
        "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVzRuSo4tAYz"
      },
      "source": [
        "def ssd_300(image_size,\n",
        "            n_classes,\n",
        "            mode='training',\n",
        "            l2_regularization=0.0005,\n",
        "            min_scale=None,\n",
        "            max_scale=None,\n",
        "            scales=None,\n",
        "            aspect_ratios_global=None,\n",
        "            aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
        "                                     [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
        "                                     [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
        "                                     [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
        "                                     [1.0, 2.0, 0.5],\n",
        "                                     [1.0, 2.0, 0.5]],\n",
        "            two_boxes_for_ar1=True,\n",
        "            steps=[8, 16, 32, 64, 100, 300],\n",
        "            offsets=None,\n",
        "            clip_boxes=False,\n",
        "            variances=[0.1, 0.1, 0.2, 0.2],\n",
        "            coords='centroids',\n",
        "            normalize_coords=True,\n",
        "            subtract_mean=[123, 117, 104],\n",
        "            divide_by_stddev=None,\n",
        "            swap_channels=[2, 1, 0],\n",
        "            confidence_thresh=0.01,\n",
        "            iou_threshold=0.45,\n",
        "            top_k=200,\n",
        "            nms_max_output_size=400,\n",
        "            return_predictor_sizes=False,\n",
        "            **kwargs):\n",
        "      #  model: The Keras SSD300 model.\n",
        "       # predictor_sizes (optional): Một numpy array chứa các phần `(height, width)` của output tensor shape tương ứng với mỗi convolutional predictor layer.\n",
        "\n",
        "    n_predictor_layers = 6 # Số lượng các preductor convolutional layers trong network là 6 cho original SSD300.\n",
        "    n_classes += 1 # Số lượng classes, + 1 để tính thêm background class.\n",
        "    l2_reg = l2_regularization # tham số chuẩn hóa của norm chuẩn l2.\n",
        "    img_height, img_width, img_channels = image_size[0], image_size[1], image_size[2]\n",
        "    if aspect_ratios_global is None and aspect_ratios_per_layer is None:\n",
        "        raise ValueError(\"`aspect_ratios_global` and `aspect_ratios_per_layer` cannot both be None. At least one needs to be specified.\")\n",
        "    if aspect_ratios_per_layer:\n",
        "        if len(aspect_ratios_per_layer) != n_predictor_layers:\n",
        "            raise ValueError(\"It must be either aspect_ratios_per_layer is None or len(aspect_ratios_per_layer) == {}, but len(aspect_ratios_per_layer) == {}.\".format(n_predictor_layers, len(aspect_ratios_per_layer)))\n",
        "    \n",
        "    # Tạo list scales\n",
        "    if (min_scale is None or max_scale is None) and scales is None:\n",
        "        raise ValueError(\"Either `min_scale` and `max_scale` or `scales` need to be specified.\")\n",
        "    if scales:\n",
        "        if len(scales) != n_predictor_layers+1:\n",
        "            raise ValueError(\"It must be either scales is None or len(scales) == {}, but len(scales) == {}.\".format(n_predictor_layers+1, len(scales)))\n",
        "    else: \n",
        "        scales = np.linspace(min_scale, max_scale, n_predictor_layers+1)\n",
        "\n",
        "    if len(variances) != 4:\n",
        "        raise ValueError(\"4 variance values must be pased, but {} values were received.\".format(len(variances)))\n",
        "    variances = np.array(variances)\n",
        "    if np.any(variances <= 0):\n",
        "        raise ValueError(\"All variances must be >0, but the variances given are {}\".format(variances))\n",
        "\n",
        "    if (not (steps is None)) and (len(steps) != n_predictor_layers):\n",
        "        raise ValueError(\"You must provide at least one step value per predictor layer.\")\n",
        "\n",
        "    if (not (offsets is None)) and (len(offsets) != n_predictor_layers):\n",
        "        raise ValueError(\"You must provide at least one offset value per predictor layer.\")\n",
        "    # Tính các tham số của anchor box.\n",
        "    ############################################################################\n",
        "\n",
        "    # Thiết lập aspect ratios cho mỗi predictor layer (chỉ cần thiết cho tính toán anchor box layers).\n",
        "    if aspect_ratios_per_layer:\n",
        "        aspect_ratios = aspect_ratios_per_layer\n",
        "    else:\n",
        "        aspect_ratios = [aspect_ratios_global] * n_predictor_layers\n",
        "\n",
        "    # Tính số lượng boxes được dự báo / 1 cell cho mỗi predictor layer.\n",
        "    # Chúng ta cần biết bao nhiêu channels các predictor layers cần có.\n",
        "    if aspect_ratios_per_layer:\n",
        "        n_boxes = []\n",
        "        for ar in aspect_ratios_per_layer:\n",
        "            if (1 in ar) & two_boxes_for_ar1:\n",
        "                n_boxes.append(len(ar) + 1) # +1 cho trường hợp aspect ratio = 1\n",
        "            else:\n",
        "                n_boxes.append(len(ar))\n",
        "    else: # Nếu chỉ 1 global aspect ratio list được truyền vào thì số lượng boxes là như nhau cho mọi layers.\n",
        "        if (1 in aspect_ratios_global) & two_boxes_for_ar1:\n",
        "            n_boxes = len(aspect_ratios_global) + 1\n",
        "        else:\n",
        "            n_boxes = len(aspect_ratios_global)\n",
        "        n_boxes = [n_boxes] * n_predictor_layers\n",
        "\n",
        "    if steps is None:\n",
        "        steps = [None] * n_predictor_layers\n",
        "    if offsets is None:\n",
        "        offsets = [None] * n_predictor_layers\n",
        "\n",
        "    ############################################################################\n",
        "    # Xác định các hàm số cho Lambda layers bên dưới.\n",
        "    ############################################################################\n",
        "\n",
        "    def identity_layer(tensor):\n",
        "        return tensor\n",
        "\n",
        "    def input_mean_normalization(tensor):\n",
        "        return tensor - np.array(subtract_mean)\n",
        "\n",
        "    def input_stddev_normalization(tensor):\n",
        "        return tensor / np.array(divide_by_stddev)\n",
        "\n",
        "    def input_channel_swap(tensor):\n",
        "        if len(swap_channels) == 3:\n",
        "            return K.stack([tensor[...,swap_channels[0]], tensor[...,swap_channels[1]], tensor[...,swap_channels[2]]], axis=-1)\n",
        "        elif len(swap_channels) == 4:\n",
        "            return K.stack([tensor[...,swap_channels[0]], tensor[...,swap_channels[1]], tensor[...,swap_channels[2]], tensor[...,swap_channels[3]]], axis=-1)\n",
        "    x = Input(shape=(img_height, img_width, img_channels))\n",
        "\n",
        "    x1 = Lambda(identity_layer, output_shape=(img_height, img_width, img_channels), name='identity_layer')(x)\n",
        "    if not (subtract_mean is None):\n",
        "        x1 = Lambda(input_mean_normalization, output_shape=(img_height, img_width, img_channels), name='input_mean_normalization')(x1)\n",
        "    if not (divide_by_stddev is None):\n",
        "        x1 = Lambda(input_stddev_normalization, output_shape=(img_height, img_width, img_channels), name='input_stddev_normalization')(x1)\n",
        "    if swap_channels:\n",
        "        x1 = Lambda(input_channel_swap, output_shape=(img_height, img_width, img_channels), name='input_channel_swap')(x1)\n",
        "    # Bước 1.1: Tính toán base network là mạng VGG16\n",
        "    conv1_1 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv1_1')(x1)\n",
        "    conv1_2 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv1_2')(conv1_1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='pool1')(conv1_2)\n",
        "\n",
        "    conv2_1 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv2_1')(pool1)\n",
        "    conv2_2 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv2_2')(conv2_1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='pool2')(conv2_2)\n",
        "\n",
        "    conv3_1 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv3_1')(pool2)\n",
        "    conv3_2 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv3_2')(conv3_1)\n",
        "    conv3_3 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv3_3')(conv3_2)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='pool3')(conv3_3)\n",
        "\n",
        "    conv4_1 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv4_1')(pool3)\n",
        "    conv4_2 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv4_2')(conv4_1)\n",
        "    conv4_3 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv4_3')(conv4_2)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='pool4')(conv4_3)\n",
        "\n",
        "    conv5_1 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv5_1')(pool4)\n",
        "    conv5_2 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv5_2')(conv5_1)\n",
        "    conv5_3 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv5_3')(conv5_2)\n",
        "    pool5 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same', name='pool5')(conv5_3)\n",
        "# Bước 1.2: Áp dụng các convolutional filter có kích thước (3 x 3) để tính toán ra features map.\n",
        "    fc6 = Conv2D(1024, (3, 3), dilation_rate=(6, 6), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='fc6')(pool5)\n",
        "    print('fully connected 6: ', fc6.get_shape())\n",
        "    fc7 = Conv2D(1024, (1, 1), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='fc7')(fc6)\n",
        "    print('fully connected 7: ', fc7.get_shape())\n",
        "    conv6_1 = Conv2D(256, (1, 1), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv6_1')(fc7)\n",
        "    conv6_1 = ZeroPadding2D(padding=((1, 1), (1, 1)), name='conv6_padding')(conv6_1)\n",
        "    conv6_2 = Conv2D(512, (3, 3), strides=(2, 2), activation='relu', padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv6_2')(conv6_1)\n",
        "    print('conv6_2: ', conv6_2.get_shape())\n",
        "    conv7_1 = Conv2D(128, (1, 1), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv7_1')(conv6_2)\n",
        "    conv7_1 = ZeroPadding2D(padding=((1, 1), (1, 1)), name='conv7_padding')(conv7_1)\n",
        "    conv7_2 = Conv2D(256, (3, 3), strides=(2, 2), activation='relu', padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv7_2')(conv7_1)\n",
        "    print('conv7_2: ', conv7_2.get_shape())\n",
        "    conv8_1 = Conv2D(128, (1, 1), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv8_1')(conv7_2)\n",
        "    conv8_2 = Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv8_2')(conv8_1)\n",
        "    print('conv8_2: ', conv8_2.get_shape())\n",
        "    conv9_1 = Conv2D(128, (1, 1), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv9_1')(conv8_2)\n",
        "    conv9_2 = Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv9_2')(conv9_1)\n",
        "    print('conv9_2: ', conv9_2.get_shape())\n",
        "    # Feed conv4_3 vào the L2 normalization layer\n",
        "    conv4_3_norm = L2Normalization(gamma_init=20, name='conv4_3_norm')(conv4_3)\n",
        "    print('conv4_3_norm.shape: ', conv4_3_norm.get_shape())        \n",
        "    # Bước 1.3: Xác định output phân phối xác suất theo các classes ứng với mỗi một default bounding box.\n",
        "    ### Xây dựng các convolutional predictor layers tại top của base network\n",
        "    # Chúng ta dự báo các giá trị confidence cho mỗi box, do đó confidence predictors có độ sâu `n_boxes * n_classes`\n",
        "    # Đầu ra của confidence layers có shape: `(batch, height, width, n_boxes * n_classes)`\n",
        "    conv4_3_norm_mbox_conf = Conv2D(n_boxes[0] * n_classes, (3, 3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv4_3_norm_mbox_conf')(conv4_3_norm)\n",
        "    print('conv4_3_norm_mbox_conf.shape: ', conv4_3_norm_mbox_conf.get_shape())\n",
        "    fc7_mbox_conf = Conv2D(n_boxes[1] * n_classes, (3, 3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='fc7_mbox_conf')(fc7)\n",
        "    print('fc7_mbox_conf.shape: ', fc7_mbox_conf.get_shape())\n",
        "    conv6_2_mbox_conf = Conv2D(n_boxes[2] * n_classes, (3, 3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv6_2_mbox_conf')(conv6_2)\n",
        "    conv7_2_mbox_conf = Conv2D(n_boxes[3] * n_classes, (3, 3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv7_2_mbox_conf')(conv7_2)\n",
        "    conv8_2_mbox_conf = Conv2D(n_boxes[4] * n_classes, (3, 3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv8_2_mbox_conf')(conv8_2)\n",
        "    conv9_2_mbox_conf = Conv2D(n_boxes[5] * n_classes, (3, 3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv9_2_mbox_conf')(conv9_2)\n",
        "    print('conv9_2_mbox_conf: ', conv9_2_mbox_conf.get_shape())\n",
        "    # Bước 1.4: Xác định output các tham số offset của default bounding boxes tương ứng với mỗi cell trên các features map.\n",
        "    # Chúng ta dự báo 4 tọa độ cho mỗi box, do đó localization predictors có độ sâu `n_boxes * 4`\n",
        "    # Output shape của localization layers: `(batch, height, width, n_boxes * 4)`\n",
        "    conv4_3_norm_mbox_loc = Conv2D(n_boxes[0] * 4, (3, 3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv4_3_norm_mbox_loc')(conv4_3_norm)\n",
        "    print('conv4_3_norm_mbox_loc: ', conv4_3_norm_mbox_loc.get_shape())\n",
        "    fc7_mbox_loc = Conv2D(n_boxes[1] * 4, (3, 3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='fc7_mbox_loc')(fc7)\n",
        "    conv6_2_mbox_loc = Conv2D(n_boxes[2] * 4, (3, 3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv6_2_mbox_loc')(conv6_2)\n",
        "    conv7_2_mbox_loc = Conv2D(n_boxes[3] * 4, (3, 3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv7_2_mbox_loc')(conv7_2)\n",
        "    conv8_2_mbox_loc = Conv2D(n_boxes[4] * 4, (3, 3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv8_2_mbox_loc')(conv8_2)\n",
        "    conv9_2_mbox_loc = Conv2D(n_boxes[5] * 4, (3, 3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv9_2_mbox_loc')(conv9_2)\n",
        "    print('conv9_2_mbox_loc: ', conv9_2_mbox_loc.get_shape())\n",
        "\n",
        "    # Bước 1.5: Tính toán các AnchorBoxes làm cơ sở để dự báo offsets cho các predicted bounding boxes bao quan vật thể\n",
        "    ############################################################################\n",
        "\n",
        "    ### Khởi tạo các anchor boxes (được gọi là \"priors\" trong code gốc Caffe/C++ của mô hình)\n",
        "    # Shape output của anchors: `(batch, height, width, n_boxes, 8)`\n",
        "    conv4_3_norm_mbox_priorbox = AnchorBoxes(img_height, img_width, this_scale=scales[0], next_scale=scales[1], aspect_ratios=aspect_ratios[0],\n",
        "                                             two_boxes_for_ar1=two_boxes_for_ar1, this_steps=steps[0], this_offsets=offsets[0], clip_boxes=clip_boxes,\n",
        "                                             variances=variances, coords=coords, normalize_coords=normalize_coords, name='conv4_3_norm_mbox_priorbox')(conv4_3_norm_mbox_loc)\n",
        "    print('conv4_3_norm_mbox_priorbox: ', conv4_3_norm_mbox_priorbox.get_shape())\n",
        "    fc7_mbox_priorbox = AnchorBoxes(img_height, img_width, this_scale=scales[1], next_scale=scales[2], aspect_ratios=aspect_ratios[1],\n",
        "                                    two_boxes_for_ar1=two_boxes_for_ar1, this_steps=steps[1], this_offsets=offsets[1], clip_boxes=clip_boxes,\n",
        "                                    variances=variances, coords=coords, normalize_coords=normalize_coords, name='fc7_mbox_priorbox')(fc7_mbox_loc)\n",
        "    print('fc7_mbox_priorbox: ', fc7_mbox_priorbox.get_shape())\n",
        "    conv6_2_mbox_priorbox = AnchorBoxes(img_height, img_width, this_scale=scales[2], next_scale=scales[3], aspect_ratios=aspect_ratios[2],\n",
        "                                        two_boxes_for_ar1=two_boxes_for_ar1, this_steps=steps[2], this_offsets=offsets[2], clip_boxes=clip_boxes,\n",
        "                                        variances=variances, coords=coords, normalize_coords=normalize_coords, name='conv6_2_mbox_priorbox')(conv6_2_mbox_loc)\n",
        "    print('conv6_2_mbox_priorbox: ', conv6_2_mbox_priorbox.get_shape())\n",
        "    conv7_2_mbox_priorbox = AnchorBoxes(img_height, img_width, this_scale=scales[3], next_scale=scales[4], aspect_ratios=aspect_ratios[3],\n",
        "                                        two_boxes_for_ar1=two_boxes_for_ar1, this_steps=steps[3], this_offsets=offsets[3], clip_boxes=clip_boxes,\n",
        "                                        variances=variances, coords=coords, normalize_coords=normalize_coords, name='conv7_2_mbox_priorbox')(conv7_2_mbox_loc)\n",
        "    print('conv7_2_mbox_priorbox: ', conv7_2_mbox_priorbox.get_shape())\n",
        "    conv8_2_mbox_priorbox = AnchorBoxes(img_height, img_width, this_scale=scales[4], next_scale=scales[5], aspect_ratios=aspect_ratios[4],\n",
        "                                        two_boxes_for_ar1=two_boxes_for_ar1, this_steps=steps[4], this_offsets=offsets[4], clip_boxes=clip_boxes,\n",
        "                                        variances=variances, coords=coords, normalize_coords=normalize_coords, name='conv8_2_mbox_priorbox')(conv8_2_mbox_loc)\n",
        "    print('conv8_2_mbox_priorbox: ', conv8_2_mbox_priorbox.get_shape())\n",
        "    conv9_2_mbox_priorbox = AnchorBoxes(img_height, img_width, this_scale=scales[5], next_scale=scales[6], aspect_ratios=aspect_ratios[5],\n",
        "                                        two_boxes_for_ar1=two_boxes_for_ar1, this_steps=steps[5], this_offsets=offsets[5], clip_boxes=clip_boxes,\n",
        "                                        variances=variances, coords=coords, normalize_coords=normalize_coords, name='conv9_2_mbox_priorbox')(conv9_2_mbox_loc)\n",
        "    print('conv9_2_mbox_priorbox: ', conv9_2_mbox_priorbox.get_shape())\n",
        "    # Bước 2: Reshape lại các output tensor shape\n",
        "\n",
        "    # Bước 2.1: Reshape output của class predictions\n",
        "    # Reshape các class predictions, trả về 3D tensors có shape `(batch, height * width * n_boxes, n_classes)`\n",
        "    # Chúng ta muốn các classes là tách biệt nhau trên last axis để tính softmax trên chúng.\n",
        "    conv4_3_norm_mbox_conf_reshape = Reshape((-1, n_classes), name='conv4_3_norm_mbox_conf_reshape')(conv4_3_norm_mbox_conf)\n",
        "    fc7_mbox_conf_reshape = Reshape((-1, n_classes), name='fc7_mbox_conf_reshape')(fc7_mbox_conf)\n",
        "    conv6_2_mbox_conf_reshape = Reshape((-1, n_classes), name='conv6_2_mbox_conf_reshape')(conv6_2_mbox_conf)\n",
        "    conv7_2_mbox_conf_reshape = Reshape((-1, n_classes), name='conv7_2_mbox_conf_reshape')(conv7_2_mbox_conf)\n",
        "    conv8_2_mbox_conf_reshape = Reshape((-1, n_classes), name='conv8_2_mbox_conf_reshape')(conv8_2_mbox_conf)\n",
        "    conv9_2_mbox_conf_reshape = Reshape((-1, n_classes), name='conv9_2_mbox_conf_reshape')(conv9_2_mbox_conf)\n",
        "    print('conv4_3_norm_mbox_conf_reshape: ', conv4_3_norm_mbox_conf_reshape.get_shape())\n",
        "    print('fc7_mbox_conf_reshape: ', fc7_mbox_conf_reshape.get_shape())\n",
        "    print('conv9_2_mbox_conf_reshape: ', conv9_2_mbox_conf_reshape.get_shape())\n",
        "    print('conv9_2_mbox_conf_reshape: ', conv9_2_mbox_conf_reshape.get_shape())\n",
        "    print('conv9_2_mbox_conf_reshape: ', conv9_2_mbox_conf_reshape.get_shape())\n",
        "    # Bước 2.2: Reshape output của bounding box predictions\n",
        "    # Reshape các box predictions, trả về 3D tensors có shape `(batch, height * width * n_boxes, 4)`\n",
        "    # Chúng ta muốn 4 tọa độ box là tách biệt nhau trên last axis để tính hàm smooth L1 loss\n",
        "    conv4_3_norm_mbox_loc_reshape = Reshape((-1, 4), name='conv4_3_norm_mbox_loc_reshape')(conv4_3_norm_mbox_loc)\n",
        "    fc7_mbox_loc_reshape = Reshape((-1, 4), name='fc7_mbox_loc_reshape')(fc7_mbox_loc)\n",
        "    conv6_2_mbox_loc_reshape = Reshape((-1, 4), name='conv6_2_mbox_loc_reshape')(conv6_2_mbox_loc)\n",
        "    conv7_2_mbox_loc_reshape = Reshape((-1, 4), name='conv7_2_mbox_loc_reshape')(conv7_2_mbox_loc)\n",
        "    conv8_2_mbox_loc_reshape = Reshape((-1, 4), name='conv8_2_mbox_loc_reshape')(conv8_2_mbox_loc)\n",
        "    conv9_2_mbox_loc_reshape = Reshape((-1, 4), name='conv9_2_mbox_loc_reshape')(conv9_2_mbox_loc)\n",
        "    print('conv4_3_norm_mbox_loc_reshape: ', conv4_3_norm_mbox_loc_reshape.get_shape())\n",
        "    print('fc7_mbox_loc_reshape: ', fc7_mbox_loc_reshape.get_shape())\n",
        "    print('conv6_2_mbox_loc_reshape: ', conv6_2_mbox_loc_reshape.get_shape())\n",
        "    print('conv7_2_mbox_loc_reshape: ', conv7_2_mbox_loc_reshape.get_shape())\n",
        "    print('conv8_2_mbox_loc_reshape: ', conv8_2_mbox_loc_reshape.get_shape())\n",
        "    print('conv9_2_mbox_loc_reshape: ', conv9_2_mbox_loc_reshape.get_shape())\n",
        "    # Bước 2.3: Reshape output của anchor bo\n",
        "    # Reshape anchor box tensors, trả về 3D tensors có shape `(batch, height * width * n_boxes, 8)`\n",
        "    conv4_3_norm_mbox_priorbox_reshape = Reshape((-1, 8), name='conv4_3_norm_mbox_priorbox_reshape')(conv4_3_norm_mbox_priorbox)\n",
        "    fc7_mbox_priorbox_reshape = Reshape((-1, 8), name='fc7_mbox_priorbox_reshape')(fc7_mbox_priorbox)\n",
        "    conv6_2_mbox_priorbox_reshape = Reshape((-1, 8), name='conv6_2_mbox_priorbox_reshape')(conv6_2_mbox_priorbox)\n",
        "    conv7_2_mbox_priorbox_reshape = Reshape((-1, 8), name='conv7_2_mbox_priorbox_reshape')(conv7_2_mbox_priorbox)\n",
        "    conv8_2_mbox_priorbox_reshape = Reshape((-1, 8), name='conv8_2_mbox_priorbox_reshape')(conv8_2_mbox_priorbox)\n",
        "    conv9_2_mbox_priorbox_reshape = Reshape((-1, 8), name='conv9_2_mbox_priorbox_reshape')(conv9_2_mbox_priorbox)\n",
        "    print('conv4_3_norm_mbox_priorbox_reshape: ', conv4_3_norm_mbox_priorbox_reshape.get_shape())\n",
        "    print('fc7_mbox_priorbox_reshape: ', fc7_mbox_priorbox_reshape.get_shape())\n",
        "    print('conv6_2_mbox_priorbox_reshape: ', conv6_2_mbox_priorbox_reshape.get_shape())\n",
        "    print('conv7_2_mbox_priorbox_reshape: ', conv7_2_mbox_priorbox_reshape.get_shape())\n",
        "    print('conv8_2_mbox_priorbox_reshape: ', conv8_2_mbox_priorbox_reshape.get_shape())\n",
        "    print('conv9_2_mbox_priorbox_reshape: ', conv9_2_mbox_priorbox_reshape.get_shape())\n",
        "     ### Concatenate các predictions từ các layers khác nhau\n",
        "    # Bước 3: Concatenate các boxes trên layers\n",
        "    # Bước 3.1: Concatenate confidence output box\n",
        "    # Axis 0 (batch) và axis 2 (n_classes hoặc 4) là xác định duy nhất cho toàn bộ các predictions layer\n",
        "    # nên chúng ta muốn concatenate theo axis 1, số lượng các boxes trên layer\n",
        "    # Output shape của `mbox_conf`: (batch, n_boxes_total, n_classes)\n",
        "    mbox_conf = Concatenate(axis=1, name='mbox_conf')([conv4_3_norm_mbox_conf_reshape,\n",
        "                                                       fc7_mbox_conf_reshape,\n",
        "                                                       conv6_2_mbox_conf_reshape,\n",
        "                                                       conv7_2_mbox_conf_reshape,\n",
        "                                                       conv8_2_mbox_conf_reshape,\n",
        "                                                       conv9_2_mbox_conf_reshape])\n",
        "    print('mbox_conf.shape: ', mbox_conf.get_shape())\n",
        "     # Bước 3.2: Concatenate location output box\n",
        "    ############################################################################\n",
        "\n",
        "    # Output shape của `mbox_loc`: (batch, n_boxes_total, 4)\n",
        "    mbox_loc = Concatenate(axis=1, name='mbox_loc')([conv4_3_norm_mbox_loc_reshape,\n",
        "                                                     fc7_mbox_loc_reshape,\n",
        "                                                     conv6_2_mbox_loc_reshape,\n",
        "                                                     conv7_2_mbox_loc_reshape,\n",
        "                                                     conv8_2_mbox_loc_reshape,\n",
        "                                                     conv9_2_mbox_loc_reshape])\n",
        "\n",
        "    print('mbox_loc.shape: ', mbox_loc.get_shape())\n",
        "\n",
        "    ############################################################################\n",
        "    # Bước 3.3: Concatenate anchor output box\n",
        "    ############################################################################\n",
        "\n",
        "    # Output shape của `mbox_priorbox`: (batch, n_boxes_total, 8)\n",
        "    mbox_priorbox = Concatenate(axis=1, name='mbox_priorbox')([conv4_3_norm_mbox_priorbox_reshape,\n",
        "                                                               fc7_mbox_priorbox_reshape,\n",
        "                                                               conv6_2_mbox_priorbox_reshape,\n",
        "                                                               conv7_2_mbox_priorbox_reshape,\n",
        "                                                               conv8_2_mbox_priorbox_reshape,\n",
        "                                                               conv9_2_mbox_priorbox_reshape])\n",
        "    \n",
        "    print('mbox_priorbox.shape: ', mbox_priorbox.get_shape())\n",
        "    # Bước 4: Tính toán output\n",
        "    # Bước 4.1 : Xây dựng các hàm loss function cho confidence\n",
        "    # tọa độ của box predictions sẽ được truyền vào hàm loss function,\n",
        "    # nhưng cho các dự báo lớp, chúng ta sẽ áp dụng một hàm softmax activation layer đầu tiên\n",
        "    mbox_conf_softmax = Activation('softmax', name='mbox_conf_softmax')(mbox_conf)\n",
        "    # Concatenate các class và box predictions và the anchors thành một large predictions vector\n",
        "    # Đầu ra của `predictions`: (batch, n_boxes_total, n_classes + 4 + 8)\n",
        "    predictions = Concatenate(axis=2, name='predictions')([mbox_conf_softmax, mbox_loc, mbox_priorbox])\n",
        "    print('predictions.shape: ', predictions.get_shape())\n",
        "    if mode == 'training':\n",
        "        model = Model(inputs=x, outputs=predictions)\n",
        "    elif mode == 'inference':\n",
        "        decoded_predictions = DecodeDetections(confidence_thresh=confidence_thresh,\n",
        "                                               iou_threshold=iou_threshold,\n",
        "                                               top_k=top_k,\n",
        "                                               nms_max_output_size=nms_max_output_size,\n",
        "                                               coords=coords,\n",
        "                                               normalize_coords=normalize_coords,\n",
        "                                               img_height=img_height,\n",
        "                                               img_width=img_width,\n",
        "                                               name='decoded_predictions')(predictions)\n",
        "        model = Model(inputs=x, outputs=decoded_predictions)\n",
        "    elif mode == 'inference_fast':\n",
        "        decoded_predictions = DecodeDetectionsFast(confidence_thresh=confidence_thresh,\n",
        "                                                   iou_threshold=iou_threshold,\n",
        "                                                   top_k=top_k,\n",
        "                                                   nms_max_output_size=nms_max_output_size,\n",
        "                                                   coords=coords,\n",
        "                                                   normalize_coords=normalize_coords,\n",
        "                                                   img_height=img_height,\n",
        "                                                   img_width=img_width,\n",
        "                                                   name='decoded_predictions')(predictions)\n",
        "        model = Model(inputs=x, outputs=decoded_predictions)\n",
        "    else:\n",
        "        raise ValueError(\"`mode` must be one of 'training', 'inference' or 'inference_fast', but received '{}'.\".format(mode))\n",
        "\n",
        "    if return_predictor_sizes:\n",
        "        predictor_sizes = np.array([conv4_3_norm_mbox_conf._keras_shape[1:3],\n",
        "                                     fc7_mbox_conf._keras_shape[1:3],\n",
        "                                     conv6_2_mbox_conf._keras_shape[1:3],\n",
        "                                     conv7_2_mbox_conf._keras_shape[1:3],\n",
        "                                     conv8_2_mbox_conf._keras_shape[1:3],\n",
        "                                     conv9_2_mbox_conf._keras_shape[1:3]])\n",
        "        return model, predictor_sizes\n",
        "    else:\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ0MM-_PGVol"
      },
      "source": [
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "from math import ceil\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# from models.keras_ssd300 import ssd_300\n",
        "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
        "from anchor_box import AnchorBoxes\n",
        "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
        "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
        "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
        "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
        "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
        "\n",
        "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
        "from data_generator.object_detection_2d_geometric_ops import Resize\n",
        "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
        "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
        "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NO2p8QmGhMV"
      },
      "source": [
        "img_height = 300\n",
        "img_width = 300\n",
        "img_channels = 3\n",
        "mean_color = [123, 117, 104]\n",
        "swap_channels = [2, 1, 0]\n",
        "n_classes = 20\n",
        "scales = [0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05]\n",
        "aspect_ratios = [[1.0, 2.0, 0.5],\n",
        "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
        "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
        "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
        "                 [1.0, 2.0, 0.5],\n",
        "                 [1.0, 2.0, 0.5]]\n",
        "two_boxes_for_ar1 = True\n",
        "steps = [8, 16, 32, 64, 100, 300]\n",
        "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
        "clip_boxes = False\n",
        "variances = [0.1, 0.1, 0.2, 0.2]\n",
        "normalize_coords = True\n",
        "# 1: Build Keras model.\n",
        "\n",
        "K.clear_session() # xóa các object tại session cũ.\n",
        "\n",
        "model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
        "                n_classes=n_classes,\n",
        "                mode='training',\n",
        "                l2_regularization=0.0005,\n",
        "                scales=scales,\n",
        "                aspect_ratios_per_layer=aspect_ratios,\n",
        "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
        "                steps=steps,\n",
        "                offsets=offsets,\n",
        "                clip_boxes=clip_boxes,\n",
        "                variances=variances,\n",
        "                normalize_coords=normalize_coords,\n",
        "                subtract_mean=mean_color,\n",
        "                swap_channels=swap_channels)\n",
        "\n",
        "# 2: Chúng ta có thể load trọng số của mô hình pretrain.\n",
        "\n",
        "weights_path = 'pretrain_model/VGG_ILSVRC_16_layers_fc_reduced.h5'\n",
        "\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "\n",
        "# 3: Khởi tạo optimizer và compile vào model.\n",
        "\n",
        "sgd = SGD(lr=0.001, momentum=0.9, decay=0.0, nesterov=False)\n",
        "\n",
        "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
        "\n",
        "model.compile(optimizer=sgd, loss=ssd_loss.compute_loss)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}